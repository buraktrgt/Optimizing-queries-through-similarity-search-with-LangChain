{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08efc99-9daf-4369-a2db-6690e0d87e47",
   "metadata": {},
   "source": [
    "# Optimizing queries about cryptocurrency through similarity search using LangChain\n",
    "\n",
    "***In this project, I used an internal source to perform similarity searches and context compression using LangChain and FAISS, allowing me to query whatever I wanted.***\n",
    "\n",
    "Source link : https://documents1.worldbank.org/curated/en/293821525702130886/pdf/Cryptocurrencies-and-blockchain.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "efbab176-9d1d-4945-9964-a1e17783cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain,SequentialChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3727b42d-2efa-4f41-b1c2-deb5f035a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DOC ---> SPLIT CHUNKS\n",
    "#EMBEDDING ---> EMBED CHUNKS -->VECTORS\n",
    "#VECTOR CHUNKS --->SAVE FAISS\n",
    "#QUERY ---> SIMILARITY SEARCH FAISS\n",
    "api_key = open(\"openai api.txt\").read()\n",
    "loader = PyPDFLoader(\"Cryptocurrencies-and-blockchain.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embedding_function = OpenAIEmbeddings(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fccb5438-3efe-4a17-a852-a6a0b2f72614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8f8c96bd-2975-4c2c-94e3-e9794dc92b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = open(\"openai api.txt\").read()\n",
    "loader = PyPDFLoader(\"Cryptocurrencies-and-blockchain.pdf\")\n",
    "documents = loader.load()\n",
    "# Split documents into chunks\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=750)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7dce8b79-1158-4dbc-9e28-d5166021c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding function\n",
    "embedding_function = OpenAIEmbeddings(api_key=api_key)\n",
    "\n",
    "# Extract text content from docs\n",
    "texts = [doc.page_content for doc in docs]\n",
    "\n",
    "# Embed chunks into vectors\n",
    "embeddings = np.array(embedding_function.embed_documents(texts)).astype('float32')\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Create a document store\n",
    "docstore = InMemoryDocstore({i: docs[i] for i in range(len(docs))})\n",
    "\n",
    "# Create a mapping from index to document IDs\n",
    "index_to_docstore_id = {i: i for i in range(len(docs))}\n",
    "\n",
    "# Create a FAISS vector store for LangChain\n",
    "db_connection = FAISS(index=index, docstore=docstore, index_to_docstore_id=index_to_docstore_id, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4c88a9e2-6bba-45cc-a3f9-2fc8d690705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2018, economic growth is projected at \n",
      "4.7 percent, gradually converging to a \n",
      "potential rate of around 4.5 -5 percent. \n",
      "Recent surveys point to a moderation in \n",
      "consumer demand, weighed down by \n",
      "rising costs and declining real wages. Rap-\n",
      "id credit expansion has increased credit \n",
      "risk and raised lending rates, pointing to a \n",
      "slowdown in credit growth in 2018.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(api_key=api_key)\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=db_connection.as_retriever(), llm=llm)\n",
    "\n",
    "question = 'Give me a summary of Turkey in the year of 2018'\n",
    "\n",
    "# Use the original retriever for the similarity search\n",
    "retrieved_documents = db_connection.similarity_search(question, k=2)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=db_connection.as_retriever())\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "\n",
    "print(compressed_docs[0].page_content if compressed_docs else \"No compressed documents found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
